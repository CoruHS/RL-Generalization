\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{cobbe2019quantifying}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{cobbe2019quantifying}
\citation{cobbe2020leveraging}
\citation{zhang2018dissection}
\citation{packer2018assessing}
\citation{tobin2017domain}
\citation{yu2020gradient}
\citation{nichol2018first}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Generalization in Reinforcement Learning}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Domain Randomization}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gradient-Based Analysis}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Setting}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Generalization Robustness Score (GRS)}{2}{subsection.3.2}\protected@file@percent }
\newlabel{sec:grs}{{3.2}{2}{Generalization Robustness Score (GRS)}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Motivation}{2}{subsubsection.3.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Definition}{3}{subsubsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Why Normalize by Training Performance?}{3}{subsubsection.3.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Practical Computation}{3}{subsubsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}Edge Case: Failed Learning}{3}{subsubsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Gradient Agreement Regularization (GAR)}{3}{subsection.3.3}\protected@file@percent }
\newlabel{sec:gar}{{3.3}{3}{Gradient Agreement Regularization (GAR)}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Motivation}{3}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Architecture Overview}{4}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces GAR training pipeline. A shared policy network collects experiences from $K$ environment variations. Gradients are computed independently for each variation, then weighted by their cosine similarity with the mean gradient. Only agreeing gradient directions pass through to update the policy.}}{4}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:architecture}{{1}{4}{GAR training pipeline. A shared policy network collects experiences from $K$ environment variations. Gradients are computed independently for each variation, then weighted by their cosine similarity with the mean gradient. Only agreeing gradient directions pass through to update the policy}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Formal Description}{4}{subsubsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.4}Why Cosine Similarity Instead of Euclidean Distance?}{5}{subsubsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.5}Why Not a Simple Average?}{5}{subsubsection.3.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Environments}{5}{subsection.4.1}\protected@file@percent }
\newlabel{sec:environments}{{4.1}{5}{Environments}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}CartPole (Dynamics Variation)}{5}{subsubsection.4.1.1}\protected@file@percent }
\citation{mnih2013playing}
\citation{schulman2017proximal}
\citation{salimans2017evolution}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}MiniGrid (Layout Variation)}{6}{subsubsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}MinAtar Space Invaders (Game Mechanics Variation)}{6}{subsubsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Algorithms}{6}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Techniques}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Evaluation Protocol}{7}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Main Results}{7}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces GRS Scores (Mean $\pm $ Std) across all conditions. \textbf  {Bold} indicates best technique per algorithm-environment pair. Higher is better. GRS $\in [0, 1]$.}}{7}{table.caption.3}\protected@file@percent }
\newlabel{tab:grs}{{1}{7}{GRS Scores (Mean $\pm $ Std) across all conditions. \textbf {Bold} indicates best technique per algorithm-environment pair. Higher is better. GRS $\in [0, 1]$}{table.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces GRS scores by technique across environments. GAR provides the largest improvements for PPO, while its effect on DQN and ES varies by environment.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:grs_comparison}{{2}{7}{GRS scores by technique across environments. GAR provides the largest improvements for PPO, while its effect on DQN and ES varies by environment}{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Evaluation Rewards (Mean $\pm $ Std) at $\delta = 0$ (training conditions). Note the inverse relationship with GRS for gradient-based methods.}}{8}{table.caption.5}\protected@file@percent }
\newlabel{tab:reward}{{2}{8}{Evaluation Rewards (Mean $\pm $ Std) at $\delta = 0$ (training conditions). Note the inverse relationship with GRS for gradient-based methods}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}GAR Significantly Improves PPO Generalization}{8}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Generalization vs. Training Performance Trade-off}{8}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Performance Degradation Curves}{9}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Normalized performance vs. variation level. Each line shows mean across 3 seeds; shaded regions show $\pm 1$ std. GAR (green) maintains higher performance at larger shifts for PPO.}}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:grs_curves}{{3}{9}{Normalized performance vs. variation level. Each line shows mean across 3 seeds; shaded regions show $\pm 1$ std. GAR (green) maintains higher performance at larger shifts for PPO}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}ES Cannot Solve Sparse Reward Tasks}{9}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Technique Effectiveness is Algorithm-Dependent}{10}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Why Does GAR Help PPO More Than DQN?}{10}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Limitations}{10}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Practical Recommendations}{10}{subsection.6.3}\protected@file@percent }
\bibstyle{plain}
\bibcite{cobbe2019quantifying}{1}
\bibcite{cobbe2020leveraging}{2}
\bibcite{mnih2013playing}{3}
\bibcite{nichol2018first}{4}
\bibcite{packer2018assessing}{5}
\bibcite{salimans2017evolution}{6}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{11}{section.7}\protected@file@percent }
\bibcite{schulman2017proximal}{7}
\bibcite{tobin2017domain}{8}
\bibcite{yu2020gradient}{9}
\bibcite{zhang2018dissection}{10}
\gdef \@abspage@last{12}
